{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fcc197c-987b-49af-a28b-4fabb8d8bca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/efs/conda_envs/StreetFighterAI/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2023 LIN Yi. All Rights Reserved.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import time \n",
    "\n",
    "import retro\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "from street_fighter_custom_wrapper import StreetFighterCustomWrapper\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from IPython import display\n",
    "import cv2\n",
    "\n",
    "def show_render(env):\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())    \n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "def save_image(image_array, filename):\n",
    "    image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(filename, image_bgr)\n",
    "\n",
    "\n",
    "RESET_ROUND = True  # Whether to reset the round when fight is over. \n",
    "RENDERING = False  # Whether to render the game screen.\n",
    "\n",
    "MODEL_NAME = r\"ppo_ryu_500000_steps\"\n",
    "MODEL_NAME = r\"ppo_ryu_2500000_steps\" # Specify the model file to load. Model \"ppo_ryu_2500000_steps_updated\" is capable of beating the final stage (Bison) of the game.\n",
    "MODEL_NAME = r\"ppo_ryu_5000000_steps\"\n",
    "\n",
    "# Model notes:\n",
    "# ppo_ryu_2000000_steps_updated: Just beginning to overfit state, generalizable but not quite capable.\n",
    "# ppo_ryu_2500000_steps_updated: Approaching the final overfitted state, cannot dominate first round but partially generalizable. High chance of beating the final stage.\n",
    "# ppo_ryu_3000000_steps_updated: Near the final overfitted state, almost dominate first round but barely generalizable.\n",
    "# ppo_ryu_7000000_steps_updated: Overfitted, dominates first round but not generalizable. \n",
    "\n",
    "RANDOM_ACTION = False\n",
    "NUM_EPISODES = 10 # Make sure NUM_EPISODES >= 3 if you set RESET_ROUND to False to see the whole final stage game.\n",
    "MODEL_DIR = r\"trained_models/\"\n",
    "\n",
    "def make_env(game, state, players=1):\n",
    "    def _init():\n",
    "        env = retro.make(\n",
    "            game=game, \n",
    "            state=state, \n",
    "            players=players,\n",
    "            use_restricted_actions=retro.Actions.FILTERED,\n",
    "            obs_type=retro.Observations.IMAGE\n",
    "        )\n",
    "        env = StreetFighterCustomWrapper(env, reset_round=RESET_ROUND, rendering=RENDERING)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# if env:\n",
    "#     env.close()\n",
    "    \n",
    "game = \"StreetFighterIISpecialChampionEdition-Genesis\"\n",
    "env = make_env(game, state=\"Champion.Level12.RyuVsBison\", players=2)()\n",
    "# model = PPO(\"CnnPolicy\", env)\n",
    "\n",
    "# env2 = make_env(game, state=\"Champion.Level12.RyuVsBison\", players=2)()\n",
    "\n",
    "if not RANDOM_ACTION:\n",
    "    model = PPO.load(os.path.join(MODEL_DIR, MODEL_NAME),  device='cuda') # env=env,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657be37e-11d3-41b3-b382-01ae03e7f9be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fighting Begins!\n",
      "\n",
      "Reward: 0.105, playerHP: 176, enemyHP:141\n",
      "Reward: -0.031, playerHP: 145, enemyHP:141\n",
      "Reward: -0.034, playerHP: 111, enemyHP:141\n",
      "Reward: -0.021, playerHP: 90, enemyHP:141\n",
      "Reward: -0.038, playerHP: 52, enemyHP:141\n",
      "Reward: -0.044, playerHP: 8, enemyHP:141\n",
      "Reward: 0.048, playerHP: 8, enemyHP:125\n",
      "Reward: -0.040, playerHP: -1, enemyHP:125\n",
      "Total reward: -0.05467350251439412\n",
      "\n",
      "Reward: 0.114, playerHP: 176, enemyHP:138\n",
      "Reward: 0.138, playerHP: 176, enemyHP:92\n",
      "Reward: -0.035, playerHP: 141, enemyHP:92\n",
      "Reward: 0.018, playerHP: 141, enemyHP:86\n",
      "Reward: 0.117, playerHP: 141, enemyHP:47\n",
      "Reward: -0.044, playerHP: 97, enemyHP:47\n",
      "Reward: 0.018, playerHP: 97, enemyHP:41\n",
      "Reward: -0.032, playerHP: 65, enemyHP:41\n",
      "Reward: -0.027, playerHP: 38, enemyHP:41\n",
      "Reward: 0.108, playerHP: 38, enemyHP:5\n",
      "Reward: -0.035, playerHP: 3, enemyHP:5\n",
      "Reward: -0.001, playerHP: -1, enemyHP:5\n",
      "Total reward: 0.33880843133623395\n",
      "\n",
      "Reward: 0.105, playerHP: 176, enemyHP:141\n",
      "Reward: -0.035, playerHP: 141, enemyHP:141\n",
      "Reward: -0.032, playerHP: 109, enemyHP:141\n",
      "Reward: 0.051, playerHP: 109, enemyHP:124\n",
      "Reward: -0.035, playerHP: 74, enemyHP:124\n",
      "Reward: -0.035, playerHP: 39, enemyHP:124\n",
      "Reward: -0.035, playerHP: 4, enemyHP:124\n",
      "Reward: -0.039, playerHP: -1, enemyHP:124\n",
      "Total reward: -0.054531332747631354\n",
      "\n",
      "Reward: 0.105, playerHP: 176, enemyHP:141\n",
      "Reward: 0.018, playerHP: 176, enemyHP:135\n",
      "Reward: -0.031, playerHP: 145, enemyHP:135\n",
      "Reward: 0.087, playerHP: 145, enemyHP:106\n",
      "Reward: 0.022, playerHP: 110, enemyHP:87\n",
      "Reward: -0.036, playerHP: 74, enemyHP:87\n",
      "Reward: -0.032, playerHP: 42, enemyHP:87\n",
      "Reward: -0.035, playerHP: 7, enemyHP:87\n",
      "Reward: -0.013, playerHP: -1, enemyHP:87\n",
      "Total reward: 0.08492586160657281\n",
      "\n",
      "Reward: 0.105, playerHP: 176, enemyHP:141\n",
      "Reward: -0.042, playerHP: 134, enemyHP:141\n",
      "Reward: -0.021, playerHP: 113, enemyHP:141\n",
      "Reward: -0.029, playerHP: 84, enemyHP:141\n",
      "Reward: -0.034, playerHP: 50, enemyHP:141\n",
      "Reward: -0.024, playerHP: 26, enemyHP:141\n",
      "Reward: -0.019, playerHP: 7, enemyHP:141\n",
      "Reward: -0.063, playerHP: -1, enemyHP:141\n",
      "Total reward: -0.12731181139261483\n",
      "\n",
      "Reward: 0.105, playerHP: 176, enemyHP:141\n",
      "Reward: -0.042, playerHP: 134, enemyHP:141\n",
      "Reward: -0.023, playerHP: 111, enemyHP:141\n",
      "Reward: -0.029, playerHP: 82, enemyHP:141\n",
      "Reward: -0.022, playerHP: 60, enemyHP:141\n",
      "Reward: -0.044, playerHP: 16, enemyHP:141\n",
      "Reward: 0.138, playerHP: 16, enemyHP:95\n",
      "Reward: 0.024, playerHP: 16, enemyHP:87\n",
      "Reward: 0.051, playerHP: 16, enemyHP:70\n",
      "Reward: -0.008, playerHP: -1, enemyHP:70\n",
      "Total reward: 0.15004312803969963\n",
      "\n",
      "Reward: 0.105, playerHP: 176, enemyHP:141\n",
      "Reward: 0.087, playerHP: 176, enemyHP:112\n",
      "Reward: -0.033, playerHP: 143, enemyHP:112\n",
      "Reward: -0.032, playerHP: 111, enemyHP:112\n",
      "Reward: -0.040, playerHP: 71, enemyHP:112\n",
      "Reward: -0.035, playerHP: 36, enemyHP:112\n",
      "Reward: 0.054, playerHP: 36, enemyHP:94\n",
      "Reward: -0.031, playerHP: 5, enemyHP:94\n",
      "Reward: 0.081, playerHP: 5, enemyHP:67\n",
      "Reward: -0.007, playerHP: -1, enemyHP:67\n",
      "Total reward: 0.14871075021290028\n",
      "\n",
      "Reward: 0.114, playerHP: 176, enemyHP:138\n",
      "Reward: -0.042, playerHP: 134, enemyHP:138\n",
      "Reward: -0.034, playerHP: 100, enemyHP:138\n",
      "Reward: -0.032, playerHP: 68, enemyHP:138\n",
      "Reward: -0.032, playerHP: 36, enemyHP:138\n",
      "Reward: 0.075, playerHP: 36, enemyHP:113\n",
      "Reward: -0.031, playerHP: 5, enemyHP:113\n",
      "Reward: -0.028, playerHP: -1, enemyHP:113\n",
      "Total reward: -0.009942315770528176\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: -0.042, playerHP: 134, enemyHP:139\n",
      "Reward: 0.105, playerHP: 134, enemyHP:104\n",
      "Reward: -0.038, playerHP: 96, enemyHP:104\n",
      "Reward: -0.038, playerHP: 58, enemyHP:104\n",
      "Reward: 0.078, playerHP: 58, enemyHP:78\n",
      "Reward: 0.078, playerHP: 58, enemyHP:52\n",
      "Reward: -0.033, playerHP: 25, enemyHP:52\n",
      "Reward: -0.005, playerHP: -1, enemyHP:52\n",
      "Total reward: 0.21629688986315\n",
      "\n",
      "Reward: 0.108, playerHP: 176, enemyHP:140\n",
      "Reward: -0.021, playerHP: 155, enemyHP:140\n",
      "Reward: -0.034, playerHP: 121, enemyHP:140\n",
      "Reward: 0.105, playerHP: 121, enemyHP:105\n",
      "Reward: -0.032, playerHP: 89, enemyHP:105\n",
      "Reward: -0.035, playerHP: 54, enemyHP:105\n",
      "Reward: -0.032, playerHP: 22, enemyHP:105\n",
      "Reward: -0.021, playerHP: 1, enemyHP:105\n",
      "Reward: -0.022, playerHP: -1, enemyHP:105\n",
      "Total reward: 0.015880755040658515\n",
      "\n",
      "Winning rate: 0.0\n",
      "Average reward for ppo_ryu_500000_steps: 0.07082068536740467\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "num_episodes = NUM_EPISODES\n",
    "episode_reward_sum = 0\n",
    "num_victory = 0\n",
    "\n",
    "action_space_per_player = 12\n",
    "\n",
    "print(\"\\nFighting Begins!\\n\")\n",
    "\n",
    "save_folder = f'./outputs/level12_{MODEL_NAME}'\n",
    "\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "image_id = 0\n",
    "for _ in range(num_episodes):\n",
    "    done = False\n",
    "    \n",
    "    if RESET_ROUND:\n",
    "        obs = env.reset()\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        timestamp = time.time()\n",
    "\n",
    "        if RANDOM_ACTION:\n",
    "            obs, reward, done, info = env.step(env.action_space.sample())\n",
    "        else:\n",
    "            action, _states = model.predict(obs)\n",
    "            \n",
    "            # action_player1, _states = model.predict(obs)\n",
    "            # action_player1 = action_player1.astype(np.int8)\n",
    "            # action = np.zeros((2*action_space_per_player), dtype=np.int8)\n",
    "            # action[:action_space_per_player] = action_player1\n",
    "            \n",
    "            obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        filename = os.path.join(save_folder, f'{image_id:8d}.png')\n",
    "        image_id += 1\n",
    "        # show_render(env)\n",
    "        image_array = env.render(mode='rgb_array')\n",
    "        save_image(image_array, filename)\n",
    "        \n",
    "        if reward != 0:\n",
    "            total_reward += reward\n",
    "            print(\"Reward: {:.3f}, playerHP: {}, enemyHP:{}\".format(reward, info['agent_hp'], info['enemy_hp']))\n",
    "        \n",
    "        if info['enemy_hp'] < 0 or info['agent_hp'] < 0:\n",
    "            done = True\n",
    "\n",
    "    if info['enemy_hp'] < 0:\n",
    "        print(\"Victory!\")\n",
    "        num_victory += 1\n",
    "\n",
    "    print(\"Total reward: {}\\n\".format(total_reward))\n",
    "    episode_reward_sum += total_reward\n",
    "\n",
    "    if not RESET_ROUND:\n",
    "        while info['enemy_hp'] < 0 or info['agent_hp'] < 0:\n",
    "        # Inter scene transition. Do nothing.\n",
    "            obs, reward, done, info = env.step([0] * 12)\n",
    "            env.render()\n",
    "\n",
    "env.close()\n",
    "print(\"Winning rate: {}\".format(1.0 * num_victory / num_episodes))\n",
    "if RANDOM_ACTION:\n",
    "    print(\"Average reward for random action: {}\".format(episode_reward_sum/num_episodes))\n",
    "else:\n",
    "    print(\"Average reward for {}: {}\".format(MODEL_NAME, episode_reward_sum/num_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69acda9-7f59-4127-8d34-bd64f089cab9",
   "metadata": {},
   "source": [
    "# convert images to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "909a4153-7a78-47f3-b72c-43f467872824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Video: 100%|██████████| 1824/1824 [00:06<00:00, 278.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from image_to_video import image_files_to_video, image_list_to_video\n",
    "\n",
    "parts = save_folder.split('//')\n",
    "parent_folder, filename = '//'.join(parts[:-1]), parts[-1]\n",
    "\n",
    "fps = 5\n",
    "video_name = os.path.join(parent_folder, f'{filename}_{fps}.mp4')\n",
    "\n",
    "image_files_to_video(video_name, save_folder, \"mp4v\", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb73c7-8738-404e-b62a-f971ef42babe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_streetfighterai",
   "language": "python",
   "name": "conda_streetfighterai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
