{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fcc197c-987b-49af-a28b-4fabb8d8bca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/efs/conda_envs/StreetFighterAI/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2023 LIN Yi. All Rights Reserved.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import time \n",
    "\n",
    "import retro\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "from street_fighter_custom_wrapper import StreetFighterCustomWrapper\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from IPython import display\n",
    "import cv2\n",
    "\n",
    "def show_render(env):\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())    \n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "def save_image(image_array, filename):\n",
    "    image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(filename, image_bgr)\n",
    "\n",
    "\n",
    "RESET_ROUND = True  # Whether to reset the round when fight is over. \n",
    "RENDERING = False  # Whether to render the game screen.\n",
    "\n",
    "MODEL_NAME = r\"ppo_ryu_500000_steps\"\n",
    "MODEL_NAME = r\"ppo_ryu_2500000_steps\" # Specify the model file to load. Model \"ppo_ryu_2500000_steps_updated\" is capable of beating the final stage (Bison) of the game.\n",
    "# MODEL_NAME = r\"ppo_ryu_5000000_steps\"\n",
    "\n",
    "# Model notes:\n",
    "# ppo_ryu_2000000_steps_updated: Just beginning to overfit state, generalizable but not quite capable.\n",
    "# ppo_ryu_2500000_steps_updated: Approaching the final overfitted state, cannot dominate first round but partially generalizable. High chance of beating the final stage.\n",
    "# ppo_ryu_3000000_steps_updated: Near the final overfitted state, almost dominate first round but barely generalizable.\n",
    "# ppo_ryu_7000000_steps_updated: Overfitted, dominates first round but not generalizable. \n",
    "\n",
    "RANDOM_ACTION = False\n",
    "NUM_EPISODES = 10 # Make sure NUM_EPISODES >= 3 if you set RESET_ROUND to False to see the whole final stage game.\n",
    "MODEL_DIR = r\"trained_models/\"\n",
    "\n",
    "def make_env(game, state, players=1):\n",
    "    def _init():\n",
    "        env = retro.make(\n",
    "            game=game, \n",
    "            state=state, \n",
    "            players=players,\n",
    "            use_restricted_actions=retro.Actions.FILTERED,\n",
    "            obs_type=retro.Observations.IMAGE\n",
    "        )\n",
    "        env = StreetFighterCustomWrapper(env, reset_round=RESET_ROUND, rendering=RENDERING)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# if env:\n",
    "#     env.close()\n",
    "    \n",
    "game = \"StreetFighterIISpecialChampionEdition-Genesis\"\n",
    "env = make_env(game, state=\"Champion.Level12.RyuVsBison\", players=1)()\n",
    "# model = PPO(\"CnnPolicy\", env)\n",
    "\n",
    "# env2 = make_env(game, state=\"Champion.Level12.RyuVsBison\", players=2)()\n",
    "\n",
    "if not RANDOM_ACTION:\n",
    "    model = PPO.load(os.path.join(MODEL_DIR, MODEL_NAME),  device='cuda') # env=env,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657be37e-11d3-41b3-b382-01ae03e7f9be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fighting Begins!\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: 0.108, playerHP: 176, enemyHP:103\n",
      "Reward: 0.081, playerHP: 176, enemyHP:76\n",
      "Reward: 0.138, playerHP: 176, enemyHP:30\n",
      "Reward: 0.528, playerHP: 176, enemyHP:-1\n",
      "Victory!\n",
      "Total reward: 0.966\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: 0.108, playerHP: 176, enemyHP:103\n",
      "Reward: 0.081, playerHP: 176, enemyHP:76\n",
      "Reward: 0.054, playerHP: 176, enemyHP:58\n",
      "Reward: 0.138, playerHP: 176, enemyHP:12\n",
      "Reward: 0.528, playerHP: 176, enemyHP:-1\n",
      "Victory!\n",
      "Total reward: 1.02\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: 0.108, playerHP: 176, enemyHP:103\n",
      "Reward: -0.040, playerHP: 136, enemyHP:103\n",
      "Reward: -0.036, playerHP: 100, enemyHP:103\n",
      "Reward: -0.033, playerHP: 67, enemyHP:103\n",
      "Reward: -0.036, playerHP: 31, enemyHP:103\n",
      "Reward: 0.099, playerHP: 31, enemyHP:70\n",
      "Reward: 0.099, playerHP: 31, enemyHP:37\n",
      "Reward: -0.019, playerHP: 12, enemyHP:37\n",
      "Reward: -0.003, playerHP: -1, enemyHP:37\n",
      "Total reward: 0.2499654977390832\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: 0.108, playerHP: 176, enemyHP:103\n",
      "Reward: 0.081, playerHP: 176, enemyHP:76\n",
      "Reward: 0.051, playerHP: 176, enemyHP:59\n",
      "Reward: 0.114, playerHP: 176, enemyHP:21\n",
      "Reward: 0.528, playerHP: 176, enemyHP:-1\n",
      "Victory!\n",
      "Total reward: 0.993\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: 0.108, playerHP: 176, enemyHP:103\n",
      "Reward: 0.081, playerHP: 176, enemyHP:76\n",
      "Reward: 0.117, playerHP: 176, enemyHP:37\n",
      "Reward: -0.031, playerHP: 145, enemyHP:37\n",
      "Reward: -0.044, playerHP: 101, enemyHP:37\n",
      "Reward: -0.021, playerHP: 80, enemyHP:37\n",
      "Reward: -0.024, playerHP: 56, enemyHP:37\n",
      "Reward: -0.049, playerHP: 7, enemyHP:37\n",
      "Reward: -0.002, playerHP: -1, enemyHP:14\n",
      "Total reward: 0.24645012139307845\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: 0.108, playerHP: 176, enemyHP:103\n",
      "Reward: 0.108, playerHP: 176, enemyHP:67\n",
      "Reward: 0.081, playerHP: 176, enemyHP:40\n",
      "Reward: 0.051, playerHP: 176, enemyHP:23\n",
      "Reward: 0.528, playerHP: 176, enemyHP:-1\n",
      "Victory!\n",
      "Total reward: 0.9870000000000001\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: 0.108, playerHP: 176, enemyHP:103\n",
      "Reward: 0.081, playerHP: 176, enemyHP:76\n",
      "Reward: 0.138, playerHP: 176, enemyHP:30\n",
      "Reward: -0.032, playerHP: 144, enemyHP:30\n",
      "Reward: 0.072, playerHP: 144, enemyHP:6\n",
      "Reward: -0.027, playerHP: 117, enemyHP:6\n",
      "Reward: -0.049, playerHP: 68, enemyHP:6\n",
      "Reward: 0.023, playerHP: 68, enemyHP:-1\n",
      "Victory!\n",
      "Total reward: 0.4245159668094526\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: 0.108, playerHP: 176, enemyHP:103\n",
      "Reward: 0.108, playerHP: 176, enemyHP:67\n",
      "Reward: 0.114, playerHP: 176, enemyHP:29\n",
      "Reward: -0.031, playerHP: 145, enemyHP:29\n",
      "Reward: -0.032, playerHP: 113, enemyHP:29\n",
      "Reward: -0.044, playerHP: 69, enemyHP:29\n",
      "Reward: -0.022, playerHP: 47, enemyHP:29\n",
      "Reward: -0.033, playerHP: 14, enemyHP:29\n",
      "Reward: -0.011, playerHP: 3, enemyHP:29\n",
      "Reward: -0.002, playerHP: -1, enemyHP:29\n",
      "Total reward: 0.265597876303807\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: 0.108, playerHP: 176, enemyHP:103\n",
      "Reward: 0.108, playerHP: 176, enemyHP:67\n",
      "Reward: 0.051, playerHP: 176, enemyHP:50\n",
      "Reward: 0.120, playerHP: 176, enemyHP:10\n",
      "Reward: -0.031, playerHP: 145, enemyHP:10\n",
      "Reward: -0.027, playerHP: 118, enemyHP:10\n",
      "Reward: -0.032, playerHP: 86, enemyHP:10\n",
      "Reward: -0.024, playerHP: 62, enemyHP:10\n",
      "Reward: -0.025, playerHP: 37, enemyHP:10\n",
      "Reward: 0.030, playerHP: 37, enemyHP:0\n",
      "Reward: -0.020, playerHP: 17, enemyHP:0\n",
      "Reward: -0.001, playerHP: -1, enemyHP:0\n",
      "Total reward: 0.3679703573770923\n",
      "\n",
      "Reward: 0.111, playerHP: 176, enemyHP:139\n",
      "Reward: 0.108, playerHP: 176, enemyHP:103\n",
      "Reward: 0.108, playerHP: 176, enemyHP:67\n",
      "Reward: 0.081, playerHP: 176, enemyHP:40\n",
      "Reward: 0.528, playerHP: 176, enemyHP:-1\n",
      "Victory!\n",
      "Total reward: 0.936\n",
      "\n",
      "Winning rate: 0.6\n",
      "Average reward for ppo_ryu_2500000_steps: 0.6456499819622513\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "num_episodes = NUM_EPISODES\n",
    "episode_reward_sum = 0\n",
    "num_victory = 0\n",
    "\n",
    "action_space_per_player = 12\n",
    "\n",
    "print(\"\\nFighting Begins!\\n\")\n",
    "\n",
    "save_folder = f'./outputs/level12_{MODEL_NAME}'\n",
    "\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "image_id = 0\n",
    "for _ in range(num_episodes):\n",
    "    done = False\n",
    "    \n",
    "    if RESET_ROUND:\n",
    "        obs = env.reset()\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        timestamp = time.time()\n",
    "\n",
    "        if RANDOM_ACTION:\n",
    "            obs, reward, done, info = env.step(env.action_space.sample())\n",
    "        else:\n",
    "            action, _states = model.predict(obs)\n",
    "            \n",
    "            # action_player1, _states = model.predict(obs)\n",
    "            # action_player1 = action_player1.astype(np.int8)\n",
    "            # action = np.zeros((2*action_space_per_player), dtype=np.int8)\n",
    "            # action[:action_space_per_player] = action_player1\n",
    "            \n",
    "            obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        filename = os.path.join(save_folder, f'{image_id:8d}.png')\n",
    "        image_id += 1\n",
    "        # show_render(env)\n",
    "        image_array = env.render(mode='rgb_array')\n",
    "        save_image(image_array, filename)\n",
    "        \n",
    "        if reward != 0:\n",
    "            total_reward += reward\n",
    "            print(\"Reward: {:.3f}, playerHP: {}, enemyHP:{}\".format(reward, info['agent_hp'], info['enemy_hp']))\n",
    "        \n",
    "        if info['enemy_hp'] < 0 or info['agent_hp'] < 0:\n",
    "            done = True\n",
    "\n",
    "    if info['enemy_hp'] < 0:\n",
    "        print(\"Victory!\")\n",
    "        num_victory += 1\n",
    "\n",
    "    print(\"Total reward: {}\\n\".format(total_reward))\n",
    "    episode_reward_sum += total_reward\n",
    "\n",
    "    if not RESET_ROUND:\n",
    "        while info['enemy_hp'] < 0 or info['agent_hp'] < 0:\n",
    "        # Inter scene transition. Do nothing.\n",
    "            obs, reward, done, info = env.step([0] * 12)\n",
    "            env.render()\n",
    "\n",
    "env.close()\n",
    "print(\"Winning rate: {}\".format(1.0 * num_victory / num_episodes))\n",
    "if RANDOM_ACTION:\n",
    "    print(\"Average reward for random action: {}\".format(episode_reward_sum/num_episodes))\n",
    "else:\n",
    "    print(\"Average reward for {}: {}\".format(MODEL_NAME, episode_reward_sum/num_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69acda9-7f59-4127-8d34-bd64f089cab9",
   "metadata": {},
   "source": [
    "# convert images to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "909a4153-7a78-47f3-b72c-43f467872824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Video: 100%|██████████| 1456/1456 [00:05<00:00, 278.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from image_to_video import image_files_to_video, image_list_to_video\n",
    "\n",
    "parts = save_folder.split('//')\n",
    "parent_folder, filename = '//'.join(parts[:-1]), parts[-1]\n",
    "\n",
    "fps = 5\n",
    "video_name = os.path.join(parent_folder, f'{filename}_{fps}.mp4')\n",
    "\n",
    "image_files_to_video(video_name, save_folder, \"mp4v\", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb73c7-8738-404e-b62a-f971ef42babe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_streetfighterai",
   "language": "python",
   "name": "conda_streetfighterai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
